{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0702d71c-4fda-445e-8102-b8e2b13672a0",
   "metadata": {},
   "source": [
    "# Basic Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63fbdc3-8960-43ad-8e40-ef34886b0975",
   "metadata": {},
   "source": [
    "На любом этапе прикидывать реалистичность данных.  \n",
    "На любом этапе очищать данные от обнаруженных неточностей, несоответствий.  \n",
    "\n",
    "Готовые \"библиотеки\" для анализа  \n",
    "!pip install pandas_profiling --upgrade  \n",
    "from pandas_profiling import ProfileReport  \n",
    "profile = ProfileReport(df)  \n",
    "profile\n",
    "\n",
    "-----\n",
    "- Предварительный просмотр данных\n",
    "  - df.sample(5)\n",
    "- Переименование полей\n",
    "  - df.columns = df.columns.str.lower().str.replace(' ',  '\\_')\n",
    "- Общее количество записей и типы столбцов\n",
    "  - df.shape, \n",
    "  - df.info()\n",
    "- Проверить пропуски\n",
    "  - df.isnull().sum(), \n",
    "  - df.isnull().mean()\n",
    "- Проверить дубликаты записей\n",
    "  - df[df.duplicated()].shape[0], \n",
    "  - df.duplicated().mean(), \n",
    "  - df.drop_duplicates(subset=None, keep=’first’, inplace=False)\n",
    "- Удалить ненужные колонки\n",
    "  - из df.columns скопировать названия во внутрь df[[]] и убирать колонки, переходя на новую строку и \"комментируя\" названия колонок. Чтобы можно было переиграть если что\n",
    "- Уникальность значений в каждом поле \n",
    "  - количество df.nunique(),\n",
    "  - и сами значения np.sort(df.field.unique()) на случай опечаток\n",
    "- Преобразование типов данных\n",
    "  - df.describe(include='object'),\n",
    "  - время df.pickup = pd.to_datetime(df.pickup),\n",
    "  - категориальные типы данных (при небольшом количестве значений?)  \n",
    "    for col in ('color', 'payment', 'pickup_borough', 'dropoff_borough'):\n",
    "    df[col] = df[col].astype('category')\n",
    "- На основе столбика с датой-временем создать столбик с датой (месяцем, годом...?)\n",
    "  - df['day'] = df.datetime_col.dt.date\n",
    "- ВременнЫе границы, пропущенные периоды\n",
    "  - df.dates.min(), df.dates.max(),\n",
    "  - df.dates.dt.to_period(\"M\").nunique() - количеством имеющихся периодов,\n",
    "  - барплот \"периоды - количество строк\" sns.countplot(df.dates.dt.to_period(\"M\"))\n",
    "\n",
    "-----\n",
    "##### Одномерный анализ\n",
    "- Посмотреть временные ряды числовых данных (средние?) (по дням, месяцам и годам?). Тенденции, периодичность.\n",
    "- Гистограмма распределения числовых данных. Посмотреть выбросы.\n",
    "- Гистограмма распределения числовых данных, в разрезе по различным категориям (пол, тип оплаты...). \n",
    "  Если категорий две, то скрипки, если больше, то полупрозрачные гистограммы (или kde)?\n",
    "- Распределение количества данных по категориальным данным sns.histplot(data=df, x='city_category'); или plt.pie(df.gender.value_counts(), labels=['M', 'F'])\n",
    "\n",
    "-----\n",
    "##### Двумерный анализ  \n",
    "- Функции распределения цели по пользователям/товарам... purchase_by_user = df.groupby('user_id')['purchase'].sum(); sns.ecdfplot(purchase_by_user.values);  \n",
    "- Гистограммы распределения числовых данных - парное совместное распределение.  \n",
    "- Диаграммы Параметры категориальные - цель (цель может быть \"разной\"? Сумма продаж на категорию, средняя сумма продаж на покупателя из категории, средний чек, среднее количество покупок на покупателя в категории...).  \n",
    "- Двумерные диаграммы. Скаттерплоты + линии регрессии, барплоты \"категориальные - числовые\". На скаттерплоте категории цветом вывести. Удобнее такое смотреть в BI-системе?  \n",
    "- Сводные таблицы \"Категория - Категория - Числовые данные (цель?)\". FasetGrid?\n",
    "- Pairplot для числовых данных sns.pairplot(df)  \n",
    "- Корреляционные матрицы df.corr().style.background_gradient(cmap='crest'). С версии 1.5.0 можно не только для числовых столбиков  \n",
    "\n",
    "-----\n",
    "- Удалить выбросы? заполнить недостающие значения? Или это уже для ML?  \n",
    "```python\n",
    "q_1, q_3 = np.nanpercentile(df.A, [25, 75])\n",
    "up_thresh = q_3 + 1.5 * diff_3_1\n",
    "low_thresh = q_1 - 1.5 * diff_3_1\n",
    "df.A[(df.A > low_thresh) * (df.A < up_thresh)]\n",
    "```  \n",
    "\n",
    "-----\n",
    "- Сопоставить данные, например, в разных таблицах на непротиворечивость: айдишники несущестующих в справочнике пользователей,\n",
    "дебиторка в 100 раз превышающая отгрузку\n",
    "\n",
    "-----\n",
    "- Присоединить новые данные (погода, курсы валют, индексы деловой активности)\n",
    "\n",
    "-----\n",
    "Самые важные признаки:\n",
    "```python\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "X = df[['Возраст', 'Длительность', 'Кампания', 'День', 'Предыдущий контакт', 'Индекс потребительских цен', 'Европейская межбанковская ставка', 'Количество сотрудников в компании']]\n",
    "y = df.iloc[:, -1]\n",
    "bestfeatures = SelectKBest(score_func = chi2, k = 'all')\n",
    "fit = bestfeatures.fit(X, y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "featureScores = pd.concat([dfcolumns, dfscores], axis = 1)\n",
    "featureScores.columns = ['Specs', 'Score']  \n",
    "print(featureScores.nlargest(10, 'Score')) \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d090f1d-dab6-4597-9956-d765c838a130",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
